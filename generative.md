| **Method**       | **Source & Year**                                                                 | **Key Ideas**                                                                                                    | **Suitability**                                                                                           | **Public Code**                                                                                     | **Performance**                                                                   | **Implementation Effort**                                                   | **Pros**                                                                                         | **Cons**                                                                                          |
|------------------|------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------|----------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| **ADA-Net**      | [Ahishali et al., 2025](https://arxiv.org/abs/2504.04271)                         | Attention-guided domain adaptation with contrastive learning. Transfers RGB→NIR style then segments trees.     | Specifically designed for dead tree segmentation from RGB to NIR domain. Excellent for domain gap issues. | [Official GitHub (coming soon)](https://github.com/meteahishali/ADA-Net) (check Kaggle page)        | Outperforms baselines (U-Net, DeepLab) by 5–10% IoU on small-data forest segmentation.          | Moderate; training GAN + segmentor needs tuning; well-targeted for your dataset.   | Handles small data well; domain shift aware; strong generalization.                           | Complex pipeline; requires image translation model; implementation may be non-trivial.           |
| **CycleGAN + U-Net** | [Zhu et al., 2017](https://arxiv.org/abs/1703.10593)                         | Learns unsupervised image translation between RGB and NIR; then segment with U-Net.                            | Suitable when paired NIR masks are scarce; used in remote sensing for cross-domain segmentation.           | [CycleGAN PyTorch](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)                         | Moderate success (~70–80% IoU); depends on translation fidelity and U-Net quality.              | High; two-stage training: GAN (CycleGAN), then segmentor.                        | Flexible for domain shift; widely used and easy-to-find codebases.                           | Requires domain-specific tuning; risk of mode collapse or poor translation.                     |
| **SimCLR + U-Net**  | [Chen et al., 2020](https://arxiv.org/abs/2002.05709) + U-Net                  | Uses self-supervised contrastive learning (SimCLR) on unlabeled aerial data; U-Net fine-tuned for segmentation. | Great for small datasets with limited labels; widely used in medical and remote sensing applications.       | [SimCLR PyTorch](https://github.com/sthalles/SimCLR) + [U-Net](https://github.com/milesial/Pytorch-UNet) | Strong performance on small-data tasks (up to +10% IoU vs vanilla U-Net in some cases).         | Moderate; requires contrastive pretraining, then segmentation fine-tuning.      | Label-efficient; improves generalization; reuses simple segmentor (U-Net).                  | Needs careful contrastive augmentation; pretraining phase adds complexity.                      |
